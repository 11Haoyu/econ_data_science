{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Machine Learning \n",
    "\n",
    "Zhentao Shi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Introduction\n",
    "\n",
    "Machine learning and artificial intelligence:\n",
    "\n",
    "* Technology or alchemy?\n",
    "* Statistics or biology?\n",
    "\n",
    "* [Tom Sargent](https://www.project-syndicate.org/commentary/artificial-intelligence-new-economic-models-by-thomas-j-sargent-2019-11)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Reference\n",
    "\n",
    "* [ISLR] James, Gareth., Witten, Daniela., Hastie, Trevor., & Tibshirani, Robert. (2017). An introduction to statistical learning.  (Open access at https://www.statlearning.com/)\n",
    "* [ESL] Friendman, Hastie and Tibshirani (2001, 2008): Elements of Statistical Learning (Open access at https://hastie.su.domains/Papers/ESLII.pdf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "* Athey (2018) \n",
    "* Mullainathan and Spiess (2017)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Supervised Learning\n",
    "\n",
    "* Connection between $X$ and $Y$\n",
    "* Regression and classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "A set of data fitting procedures focusing on out-of-sample prediction\n",
    "* Repeat a scientific experiment for $n$ times and obtain a dataset $(y_i, x_i)_{i=1}^n$.\n",
    "* How to best predict $y_{n+1}$ given $x_{n+1}$?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Unsupervised Learning\n",
    "\n",
    "* Only about $X$\n",
    "* Density estimation, principal component analysis, and clustering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "\n",
    "# Conventional Statistics\n",
    "\n",
    "* Consistency\n",
    "* Asymptotic distribution (hopefully normal)\n",
    "* Efficiency"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# Machine Learning's Responses\n",
    "\n",
    "* Efficiency is mostly irrelevant given big data\n",
    "* Statistical inference may not be the goal\n",
    "    * Recommendation system on Amazon or Taobao\n",
    "    * Care about the prediction accuracy, not the causal link\n",
    "* Is there a data generating process (DGP)?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# First Generation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Nonparametric Estimation\n",
    "\n",
    "* *Parametric*: a finite number of parameters\n",
    "* *Nonparametric*: an infinite number of parameters\n",
    "\n",
    "* Some ideas in nonparametric estimation is directly related to machine learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Example: Density Estimation\n",
    "\n",
    "* Density estimation given a sample $(x_1,\\ldots,x_n)$\n",
    "* If drawn from a parametric family, MLE for estimation\n",
    "* Misspecification "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "* Histogram is nonparametric\n",
    "    * If grid too fine, small bias but large variance\n",
    "    * If grid too coarse, small variance but large bias\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    },
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA0gAAANICAMAAADKOT/pAAAADFBMVEUAAADT09P/AAD////u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\ngAAQCQABIBIAAvwDd2iWC1g5I9cAAAAASUVORK5CYII=",
      "text/plain": [
       "Plot with title \"\""
      ]
     },
     "metadata": {
      "image/png": {
       "height": 420,
       "width": 420
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "n <- 200\n",
    "\n",
    "par(mfrow = c(3, 3))\n",
    "par(mar = c(1, 1, 1, 1))\n",
    "\n",
    "x_base <- seq(0.01,1,by = 0.01)\n",
    "breaks_list = c(4, 12, 60)\n",
    "\n",
    "for (ii in 1:3){\n",
    "  x <- rbeta(n, 2, 2) # beta distribution\n",
    "  for ( bb in breaks_list){\n",
    "    hist(x, breaks = bb, main=\"\", freq = FALSE, ylim = c(0,3),xlim = c(0,1))\n",
    "    lines( y = dbeta( x_base, 2, 2), x = x_base , col = \"red\" )\n",
    "  }\n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Variance-Bias Tradeoff\n",
    "\n",
    "![](graph/bias_variance.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Example: Conditional Mean\n",
    "\n",
    "* Conditional mean $$f(x) = E[y_i |x_i = x]$$ given a sample $(y_i, x_i)$. \n",
    "* Solve \n",
    "$$\n",
    "\\min_f E[ (y_i - f(x_i) )^2 ]\n",
    "$$\n",
    "* In general $f(x)$ is a nonlinear function."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "* Restrict the class of functions to search for minimizer\n",
    "    * Assume differentiability\n",
    "* One way is kernel method based on density estimation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Series Estimation\n",
    "\n",
    "* Series expansion to approximate $f(x)$\n",
    "* Generates many additive regressors\n",
    "    * Ex: bounded, continuous and differentiate function has a series\n",
    "representation $f(x) = \\sum_{k=0}^{\\infty} \\beta_k \\cos (\\frac{k}{2}\\pi x )$.\n",
    "    * In finite sample, choose a finite $K$, usually much smaller than $n$\n",
    "    * Asymptotically $K \\to \\infty$ as $n \\to \\infty$ so that\n",
    "$$\n",
    "f_K(x) = \\sum_{k=0}^{K} \\beta_k \\cos \\left(\\frac{k}{2}\\pi x \\right) \\to f(x).\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "* Bias-variance trade-off\n",
    "    * Big $K$: small bias and large variance \n",
    "    * Small $K$: small variance and large bias"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Penalization\n",
    "\n",
    "* Specify a sufficiently large $K$, and then add a penalty term to control the complexity\n",
    "* Eg: *Ridge regression*: \n",
    "$$\n",
    "\\min_\\beta \\  \\frac{1}{2n}  \\sum_{i=1}^n \\left(y_i - \\sum_{k=0}^{K} \\beta_k f_k(x_i) \\right)^2\n",
    "+ \\lambda \\sum_{k=0}^K \\beta_k^2,\n",
    "$$\n",
    "where $\\lambda$ is the tuning parameter such that $\\lambda \\to 0$ as $n\\to \\infty$, and\n",
    "$f_k(x_i) = \\cos \\left(\\frac{k}{2}\\pi x_i \\right)$. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "In compact notation, let $Y=(y_1,\\ldots,y_n)'$ and\n",
    "$X = (X_{ik} = f_k(x_i) )$, the above problem can be written as\n",
    "$$\n",
    "(2n)^{-1} (Y-X\\beta)'(Y-X\\beta) + \\lambda \\Vert \\beta \\Vert_2 ^2\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Tuning Parameter\n",
    "\n",
    "* *Information criterion*: AIC, BIC\n",
    "* *Cross validation*\n",
    "\n",
    "\n",
    "* Active statistical research, but has little economics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Econometrics Workflow\n",
    "\n",
    "![](graph/metric_flow.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Data Splitting\n",
    "\n",
    "![ ](graph/ML_flow.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Data Splitting\n",
    "\n",
    "\n",
    "* Machine learning's main purpose is often prediction\n",
    "* Agnostic about the DGP.\n",
    "* Models are measured by their performance in prediction.\n",
    "* Tuning."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "* Training dataset\n",
    "* Validation dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "* Testing sample"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# `Caret` Package\n",
    "\n",
    "* R package `caret` (Classification And REgression Training): a framework for many machine learning methods\n",
    "* The function [`createDataPartition`](https://topepo.github.io/caret/data-splitting.html)\n",
    "splits the sample for both cross sectional data and time series."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Cross Validation (cross sectional data)\n",
    "\n",
    "* $S$-fold cross validation partitions the dataset into $S$ disjoint sections\n",
    "* Each iteration picks one of the sections as the (quasi) validation sample\n",
    "* The other $S-1$ sections as the training sample.\n",
    "* Compute an out-of-sample goodness-of-fit measurement"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Goodness of Fit (Out of Sample)\n",
    "\n",
    "* *Mean-squared prediction error* ${n_v}^{-1} \\sum_{i \\in val} (y_i - \\hat{y}_i)^2$ where $val$ is the validation set and $n_v$ is its cardinality, \n",
    "* *Mean-absolute prediction error* ${n_v}^{-1}\\sum_{i \\in val} |y_i - \\hat{y}_i|$. \n",
    "* *Out of sample R-squared* (OOS $R^2$):\n",
    "\n",
    "$$\n",
    "1 - \\frac{{n_v}^{-1} \\sum_{i \\in val} (y_i - \\hat{y}_i)^2}{{n_v}^{-1} \\sum_{i \\in val} y_i^2}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "* Repeat this process for $S$ times so that each of the $S$ sections are treated as the validation sample, \n",
    "* Average the goodness-of-fit measurement over the $S$ sections to determined the best tuning parameter. \n",
    "* In practice we can use  $S=5$ for 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Cross Validation (time series data)\n",
    "\n",
    "* In time series context, cross validation must preserve the dependence structure. \n",
    "* If the time series is stationary, we can partition the data into $S$ consecutive blocks. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "(i will skip this slide)\n",
    "\n",
    "* If the purpose is forecasting, then we can use nested CV. \n",
    "![ ](graph/CV_Figure.png)\n",
    "\n",
    "* Nested CV with fixed-length rolling window scheme\n",
    "* The sub-training data can also be an extending rolling window."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Variable Selection\n",
    "\n",
    "* Number of covariates $x_i$ can be large.\n",
    "\n",
    "* Conventional attitude: prior knowledge\n",
    "* Recently economists wake up from the long lasting negligence.\n",
    "    * Stock and Watson (2012): forecasting 143 US macroeconomic indicators.\n",
    "    * A horse race of several variable selection methods."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Lasso\n",
    "\n",
    "* least-absolute-shrinkage-and-selection-operator\n",
    "(Lasso) (Tibshirani, 1996)\n",
    "* Penalizes the $L_1$ norm of the coefficients.\n",
    "The criterion function of Lasso is written as\n",
    "$$\n",
    "(2n)^{-1} (Y-X\\beta)'(Y-X\\beta) + \\lambda \\Vert \\beta \\Vert_1\n",
    "$$\n",
    "where $\\lambda \\geq 0$ is a tuning parameter. \n",
    "\n",
    "Lasso shrinks some coefficients exactly to 0, in a wide range of values of $\\lambda$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "\n",
    "![ ](graph/lasso_regression2.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# SCAD\n",
    "\n",
    "* Smoothly-clipped-absolute-deviation (SCAD) Fan and Li (2001):\n",
    "$$\n",
    "(2n)^{-1} (Y-X\\beta)'(Y-X\\beta) + \\sum_{j=1}^d \\rho_{\\lambda}( |\\beta_j| )\n",
    "$$\n",
    "where\n",
    "$$\n",
    "\\rho_{\\lambda}^{\\prime} (\\theta) = \\lambda \\left\\{ 1\\{\\theta\\leq \\lambda \\} +\n",
    "\\frac{(a\\lambda - \\theta)_+}{(a-1)\\lambda} \\cdot 1 \\{\\theta > \\lambda\\} \\right\\}\n",
    "$$\n",
    "for some $a>2$ and $\\theta>0$. \n",
    "\n",
    "* SCAD enjoys *oracle property*. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Adaptive Lasso\n",
    "\n",
    "*Adaptive Lasso* (Zou, 2006) also enjoys the oracle property.\n",
    "\n",
    "Two-step algorithm:\n",
    "1. First run a Lasso or ridge regression and save the estimator $\\hat{\\beta}^{(1)}$\n",
    "2. Solve \n",
    "\n",
    "$$\n",
    "(2n)^{-1} (Y-X\\beta)'(Y-X\\beta) + \\lambda \\sum_{j=1}^d  w_j |\\beta_j|\n",
    "$$ \n",
    "\n",
    "where $w_j = 1 /  |\\hat{\\beta}_j^{(1)} |^a$ and $a\\geq 1$ is a constant. (Common choice is $a = 1$ or 2).\n",
    "\n",
    "* Lee, Shi and Gao (2022)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "R packages\n",
    "\n",
    "* `glmnet` or `LARS` implements Lasso\n",
    "* `ncvreg` carries out SCAD. \n",
    "* Adaptive Lasso by setting the weight via the argument `penalty.factor` in `glmnet`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    },
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] 4.273546 4.259028 8.932815\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA0gAAANICAMAAADKOT/pAAAAOVBMVEUAAAAAAP8A/wBNTU1o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\nkAABQgIECPertwAAAAAISURBVAkQ+A/jNLagbqnfiwAAAABJRU5ErkJggg==",
      "text/plain": [
       "plot without title"
      ]
     },
     "metadata": {
      "image/png": {
       "height": 420,
       "width": 420
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "library(magrittr)\n",
    "n <- 40\n",
    "p <- 50\n",
    "b0 <- c(rep(1, 10), rep(0, p - 10))\n",
    "x <- matrix(rnorm(n * p), n, p)\n",
    "y <- x %*% b0 + rnorm(n)\n",
    "\n",
    "ols <- MASS::ginv(t(x) %*% x) %*% (t(x) %*% y) # OLS\n",
    "# Implement Lasso by glmnet\n",
    "cv_lasso <- glmnet::cv.glmnet(x, y)\n",
    "lasso_result <- glmnet::glmnet(x, y, lambda = cv_lasso$lambda.min)\n",
    "\n",
    "# Get weights\n",
    "b_temp <- as.numeric(lasso_result$beta)\n",
    "b_temp[b_temp == 0] <- 1e-8\n",
    "w <- 1 / abs(b_temp) # Let gamma = 1\n",
    "\n",
    "# Implement Adaptive Lasso by glmnet\n",
    "cv_alasso <- glmnet::cv.glmnet(x, y, penalty.factor = w)\n",
    "alasso_result <-\n",
    "  glmnet::glmnet(x, y, penalty.factor = w, lambda = cv_alasso$lambda.min)\n",
    "\n",
    "plot(b0, ylim = c(-0.8, 1.5), pch = 4, xlab = \"\", ylab = \"coefficient\")\n",
    "points(lasso_result$beta, col = \"red\", pch = 6)\n",
    "points(alasso_result$beta, col = \"blue\", pch = 5)\n",
    "points(ols, col = \"green\", pch = 3)\n",
    " \n",
    "# out of sample prediction\n",
    "x_new <- matrix(rnorm(n * p), n, p)\n",
    "y_new <- x_new %*% b0 + rnorm(n)\n",
    "lasso_msfe <- (y_new - predict(lasso_result, newx = x_new)) %>% var()\n",
    "alasso_msfe <- (y_new - predict(alasso_result, newx = x_new)) %>% var()\n",
    "ols_msfe <- (y_new - x_new %*% ols) %>% var()\n",
    "\n",
    "print(c(lasso_msfe, alasso_msfe, ols_msfe))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### DIY Lasso by `CVXR`. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    },
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning message:\n",
      "\"package 'CVXR' was built under R version 4.2.3\"\n",
      "\n",
      "Attaching package: 'CVXR'\n",
      "\n",
      "\n",
      "The following object is masked from 'package:stats':\n",
      "\n",
      "    power\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [1]  7.836292e-01  4.909321e-01  7.285535e-01  6.610488e-01  3.600521e-01\n",
      " [6]  1.470885e+00  7.780719e-01  7.896610e-01  1.129968e+00  6.880147e-01\n",
      "[11] -1.616845e-22  2.852661e-22  3.711087e-22 -3.316071e-22 -1.379906e-02\n",
      "[16] -1.628364e-22 -1.499809e-22 -3.569860e-22 -2.430960e-02 -1.155485e-22\n",
      "[21] -8.768656e-02  6.261535e-23 -1.045360e-01  6.015717e-23 -2.934565e-01\n",
      "[26]  2.274072e-22  8.933526e-23  3.727675e-23 -1.297585e-22  5.624980e-22\n",
      "[31]  1.254969e-23 -4.381265e-01  3.719543e-22 -1.595437e-22 -4.208724e-22\n",
      "[36]  4.701589e-23 -1.433162e-01 -3.270297e-22 -1.785107e-22 -1.169864e-22\n",
      "[41]  1.831003e-01 -1.493608e-22  1.034732e-22  1.367101e-22 -3.049205e-22\n",
      "[46] -4.921756e-04  5.170777e-22 -9.103741e-22  3.236104e-23  3.682813e-22\n"
     ]
    }
   ],
   "source": [
    "library(CVXR)\n",
    "\n",
    "lambda <- 2 * cv_lasso$lambda.min # tuning parameter\n",
    "\n",
    "# CVXR for Lasso\n",
    "beta_cvxr <- Variable(p)\n",
    "obj <- sum_squares(y - x %*% beta_cvxr) / (2 * n) + lambda * p_norm(beta_cvxr, 1)\n",
    "prob <- Problem(Minimize(obj))\n",
    "lasso_cvxr <- solve(prob)\n",
    "beta_cvxr_hat <- lasso_cvxr$getValue(beta_cvxr) %>% as.vector() %>% print()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Stagewise Forward Selection\n",
    "\n",
    "More methods are available if prediction of the response variables is the sole purpose of the regression.\n",
    "\n",
    "Eg: *stagewise forward selection*\n",
    "\n",
    "1. Start from an empty model. \n",
    "2. Given many candidate $x_j$, in each round we add the regressor that can\n",
    "produce the biggest $R^2$. \n",
    "\n",
    "Close to the idea of *$L_2$ componentwise boosting*\n",
    "which does not adjust the coefficients fitted earlier\n",
    "\n",
    "* Shi and Huang (2023)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "\n",
    "# Second Generation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Prediction-Oriented Methods\n",
    "\n",
    "* Methods that induces data-driven interaction of the covariates.\n",
    "* Interaction makes the covariates much more flexible\n",
    "* Insufficient theoretical understanding\n",
    "* \"Black-boxes\" methods\n",
    "\n",
    "* Surprisingly superior performance\n",
    "* Industry insiders are pondering \"alchemy\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Regression Tree\n",
    "\n",
    "* Supervised learning: $x \\to y $\n",
    "* Traditional nonparametric methods: kernel or series\n",
    "\n",
    "* Regression tree (Breiman, 1984) recursively partitions the space of the regressors\n",
    "    * Each time a covariate is split into two dummies\n",
    "    * Splitting criterion is aggressive reduction of the SSR\n",
    "    \n",
    "    * Tuning parameter is the depth of the tree\n",
    "    * Given a dataset $d$ and the depth of the tree, the fitted tree $\\hat{r}(d)$ is deterministic\n",
    "\n",
    "\n",
    "- Example: Using longitude and latitude for Beijing housing price."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Bagging\n",
    "\n",
    "* Tree is unstable\n",
    "* *Bootstrap averaging*, or *bagging*, reduces variance of trees (Breiman, 1996)\n",
    "    * Grow a tree for each bootstrap sample\n",
    "    * Simple average\n",
    "\n",
    "* An example of the *ensemble learning*."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "* Inoue and Kilian (2008): an early application of bagging in time series forecast.\n",
    "* Hirano and Wright (2017): a theoretical perspective on the risk reduction of bagging."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Random Forest\n",
    "\n",
    "* *Random forest* (Breiman, 2001):\n",
    "    * Draw a bootstrap sample\n",
    "    * Before each split, shakes up the regressors by randomly sampling $m$ out of the total $p$ covarites. Stop until the depth of the tree is reached.\n",
    "    * Average the trees over the bootstrap samples\n",
    "    \n",
    "* The tuning parameters are the tree depth and $m$\n",
    "* More stable than bagging thanks to \"de-correlation\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    },
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading required package: randomForest\n",
      "\n",
      "Warning message:\n",
      "\"package 'randomForest' was built under R version 4.2.3\"\n",
      "randomForest 4.7-1.1\n",
      "\n",
      "Type rfNews() to see new features/changes/bug fixes.\n",
      "\n",
      "The following objects are masked from Boston (pos = 4):\n",
      "\n",
      "    age, black, chas, crim, dis, indus, lstat, medv, nox, ptratio, rad,\n",
      "    rm, tax, zn\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table class=\"dataframe\">\n",
       "<caption>A matrix: 13 × 1 of type dbl</caption>\n",
       "<thead>\n",
       "\t<tr><th></th><th scope=col>IncNodePurity</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "\t<tr><th scope=row>crim</th><td>1373.07707</td></tr>\n",
       "\t<tr><th scope=row>zn</th><td> 247.35123</td></tr>\n",
       "\t<tr><th scope=row>indus</th><td>1326.18996</td></tr>\n",
       "\t<tr><th scope=row>chas</th><td>  47.87453</td></tr>\n",
       "\t<tr><th scope=row>nox</th><td>1527.38467</td></tr>\n",
       "\t<tr><th scope=row>rm</th><td>6075.29521</td></tr>\n",
       "\t<tr><th scope=row>age</th><td>1031.69446</td></tr>\n",
       "\t<tr><th scope=row>dis</th><td>1551.31102</td></tr>\n",
       "\t<tr><th scope=row>rad</th><td> 164.36409</td></tr>\n",
       "\t<tr><th scope=row>tax</th><td> 788.77341</td></tr>\n",
       "\t<tr><th scope=row>ptratio</th><td>1345.75212</td></tr>\n",
       "\t<tr><th scope=row>black</th><td> 526.37109</td></tr>\n",
       "\t<tr><th scope=row>lstat</th><td>6214.98744</td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "A matrix: 13 × 1 of type dbl\n",
       "\\begin{tabular}{r|l}\n",
       "  & IncNodePurity\\\\\n",
       "\\hline\n",
       "\tcrim & 1373.07707\\\\\n",
       "\tzn &  247.35123\\\\\n",
       "\tindus & 1326.18996\\\\\n",
       "\tchas &   47.87453\\\\\n",
       "\tnox & 1527.38467\\\\\n",
       "\trm & 6075.29521\\\\\n",
       "\tage & 1031.69446\\\\\n",
       "\tdis & 1551.31102\\\\\n",
       "\trad &  164.36409\\\\\n",
       "\ttax &  788.77341\\\\\n",
       "\tptratio & 1345.75212\\\\\n",
       "\tblack &  526.37109\\\\\n",
       "\tlstat & 6214.98744\\\\\n",
       "\\end{tabular}\n"
      ],
      "text/markdown": [
       "\n",
       "A matrix: 13 × 1 of type dbl\n",
       "\n",
       "| <!--/--> | IncNodePurity |\n",
       "|---|---|\n",
       "| crim | 1373.07707 |\n",
       "| zn |  247.35123 |\n",
       "| indus | 1326.18996 |\n",
       "| chas |   47.87453 |\n",
       "| nox | 1527.38467 |\n",
       "| rm | 6075.29521 |\n",
       "| age | 1031.69446 |\n",
       "| dis | 1551.31102 |\n",
       "| rad |  164.36409 |\n",
       "| tax |  788.77341 |\n",
       "| ptratio | 1345.75212 |\n",
       "| black |  526.37109 |\n",
       "| lstat | 6214.98744 |\n",
       "\n"
      ],
      "text/plain": [
       "        IncNodePurity\n",
       "crim    1373.07707   \n",
       "zn       247.35123   \n",
       "indus   1326.18996   \n",
       "chas      47.87453   \n",
       "nox     1527.38467   \n",
       "rm      6075.29521   \n",
       "age     1031.69446   \n",
       "dis     1551.31102   \n",
       "rad      164.36409   \n",
       "tax      788.77341   \n",
       "ptratio 1345.75212   \n",
       "black    526.37109   \n",
       "lstat   6214.98744   "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA0gAAANICAMAAADKOT/pAAAAMFBMVEUAAABNTU1oaGh8fHyM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\nQYCQIEBIECAkCBASBAgJAoQEAUKCgP8BRgayn9uluFYAAAAASUVORK5CYII=",
      "text/plain": [
       "Plot with title \"Boston.rf\""
      ]
     },
     "metadata": {
      "image/png": {
       "height": 420,
       "width": 420
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "require(randomForest)\n",
    "require(MASS)#Package which contains the Boston housing dataset\n",
    "attach(Boston)\n",
    "set.seed(101)\n",
    "\n",
    "#training Sample with 300 observations\n",
    "train=sample(1:nrow(Boston),300)\n",
    "\n",
    "Boston.rf=randomForest(medv ~ . , data = Boston, subset = train)\n",
    "plot(Boston.rf)\n",
    "\n",
    "# getTree(Boston.rf)\n",
    "importance(Boston.rf)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "* Consistency of random forest is not proved\n",
    "until Scornet, Biau, and Vert (2015)\n",
    "* Inferential theory was first established by\n",
    "Wager Athey (2018)  in the context of treatment effect estimation\n",
    "* Athey, Tibshirani, and Wager (2019) generalizes CART to local maximum likelihood."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Gradient Boosting\n",
    "\n",
    "* Bagging and random forest use equal weight on each generated tree for the ensemble\n",
    "* Tree boosting takes a deterministic approach for the weights\n",
    "    1. Use the original data $d^0=(x_i,y_i)$ to grow a shallow tree $\\hat{r}^{0}(d^0)$. Save the prediction $f^0_i = \\alpha \\cdot \\hat{r}^0 (d^0, x_i)$ where\n",
    "   $\\alpha\\in [0,1]$ is a shrinkage tuning parameter. Save\n",
    "   the residual $e_i^{0} = y_i - f^0_i$. Set $m=1$.\n",
    "    2. In the $m$-th iteration, use the data $d^m = (x_i,e_i^{m-1})$ to grow a shallow tree $\\hat{r}^{m}(d^m)$. Save the prediction $f^m_i =  f^{m-1}_i +  \\alpha \\cdot \\hat{r}^m (d, x_i)$. Save\n",
    "   the residual $e_i^{m} = y_i - f^m_i$. Update $m = m+1$.\n",
    "    3. Repeat Step 2 until $m > M$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "* Boosting has three tuning parameters: the tree depth,  the shrinkage level $\\alpha$, and the number of iterations $M$\n",
    "* The algorithm can be sensitive to any of the three tuning parameters\n",
    "* When a model is tuned well, it can performs remarkably\n",
    "    * Example: Beijing housing data.\n",
    "    * Gradient boosting via the package `gbm`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Statisticians view boosting as a gradient descent algorithm to reduce the risk. The fitted\n",
    "tree in each iteration is the deepest descent direction, while the shrinkage tames the fitting to avoid proceeding too aggressively."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Real Data Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    },
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "library(caret)\n",
    "\n",
    "\n",
    "load(\"data_example/lianjia.RData\")\n",
    "N <- nrow(lianjia) # a smaller sample\n",
    "lianjia <- lianjia[base::sample(1:N, round(N * 0.05 )), ]\n",
    "\n",
    "train_ind <- caret::createDataPartition(1:nrow(lianjia), p = 0.1)$Resample1\n",
    "# p = 0.1 to save time. Better to use p = 0.75\n",
    "\n",
    "gbmGrid <- expand.grid(\n",
    "  interaction.depth = seq(from = 10, to = 50, by = 30),\n",
    "  n.trees = seq(from = 1000, to = 10000, by = 4000),\n",
    "  shrinkage = c(0.01),\n",
    "  n.minobsinnode = 20\n",
    ")\n",
    "\n",
    "gbmControl <- caret::trainControl(method = \"cv\", number = 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    },
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "formula.GBM <- price ~\n",
    "  square + livingRoom + drawingRoom + kitchen + bathRoom +\n",
    "  floor_type + floor_total + elevator + ladderRatio +\n",
    "  age + DOM + followers + fiveYearsProperty +\n",
    "  subway + district + Lng + Lat + t_trade +\n",
    "  communityAverage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    },
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time Cost of Finding Best Tuning Parameters: 1.615394 \n"
     ]
    }
   ],
   "source": [
    "library(doParallel)\n",
    "library(gbm)\n",
    "\n",
    "gbmControl=trainControl(method=\"repeatedcv\",number=5,repeats=1)\n",
    "\n",
    "registerDoParallel(8)\n",
    "t=Sys.time()\n",
    "boostingReg=train(formula.GBM, \n",
    "                  data=lianjia[train_ind,],\n",
    "                  method=\"gbm\",\n",
    "                  distribution=\"gaussian\",\n",
    "                  trControl=gbmControl,\n",
    "                  tuneGrid=gbmGrid,\n",
    "                  metric=\"Rsquared\",\n",
    "                  verbose=F)\n",
    "cat(\"Time Cost of Finding Best Tuning Parameters:\",Sys.time()-t,\"\\n\")\n",
    "doParallel::stopImplicitCluster()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    },
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The best tuning parameters for GBM are: \n",
      "  n.trees interaction.depth shrinkage n.minobsinnode\n",
      "1    1000                10      0.01             20\n"
     ]
    }
   ],
   "source": [
    "gbmTune = boostingReg$bestTune\n",
    "cat(\"The best tuning parameters for GBM are: \\n\");\n",
    "print(gbmTune)\n",
    "\n",
    "pred.boosting=predict(boostingReg,newdata=lianjia[-train_ind,])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    },
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R-squared of GBM prediction = 0.9164412 \n",
      "R-squared of LM prediction = 0.8261253 \n"
     ]
    }
   ],
   "source": [
    "lmReg=lm(formula.GBM, data=lianjia[train_ind,])\n",
    "pred.lm=predict(lmReg,newdata=lianjia[-train_ind,])\n",
    "\n",
    "\n",
    "# Comparison\n",
    "\n",
    "target=lianjia[-train_ind,]$price\n",
    "cat(\"R-squared of GBM prediction =\",miscTools::rSquared(target,target-pred.boosting),\"\\n\")\n",
    "cat(\"R-squared of LM prediction =\",miscTools::rSquared(target,target-pred.lm),\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "* Many variants of boosting algorithms\n",
    "    * $L_2$-boosting\n",
    "    * componentwise boosting\n",
    "    * AdaBoosting, etc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Neural Network\n",
    "\n",
    "* Artificial neural network (ANN) is the workhorse behind Alpha-Go and self-driven cars\n",
    "* A particular type of nonlinear models.\n",
    "\n",
    "![ANN](graph/Colored_neural_network.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "* The transition from layer $k-1$ to layer $k$ can be written as\n",
    "\n",
    "$$\n",
    "\\begin{eqnarray*}\n",
    "z_l^{(k)} & = & w_{l0}^{(k-1)} + \\sum_{j=1}^{p_{k-1} } w_{lj}^{(k-1)} a_j^{(k-1)} \\\\ \n",
    "a_l^{(k)} & = & g^{(k)} ( z_l^{(k)}), \n",
    "\\end{eqnarray*}\n",
    "$$\n",
    "\n",
    "where $ a_j^{(0)} = x_j$ is the input.\n",
    "\n",
    "* The latent variable $z_l^{(k)}$ usually takes a linear form\n",
    "* *Activation function* $g(\\cdot)$ is usually a simple nonlinear function\n",
    "* Popular choice: sigmoid ($1/(1+\\exp(-x))$); ReLu, $z\\cdot 1\\{x\\geq 0\\}$)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "A user has several decisions to make\n",
    "* Activation function\n",
    "* Number of hidden layers\n",
    "* Number of nodes in each layer\n",
    "\n",
    "\n",
    "* Many free parameters are generated from the multiple layer and multiple nodes\n",
    "* In estimation often regularization methods are employed to penalize\n",
    "the $l_1$ and/or $l_2$ norms, which requires extra tuning parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "#  Theory is Underdeveloped\n",
    "\n",
    "* Theoretical understanding about its behavior is scant\n",
    "* Hornik, Stinchcombe, and White (1989):\n",
    "    * A single hidden layer neural network, given enough many nodes, is a *universal approximator* for any\n",
    "measurable function."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Computation\n",
    "\n",
    "* Free parameters must be determined by\n",
    "numerical optimization\n",
    "* Nonlinear complex structure makes the optimization\n",
    "very challenging and the global optimizer is beyond guarantee\n",
    "* De facto optimization algorithm\n",
    "is *stochastic gradient descent*\n",
    "\n",
    "* Google's `tensorflow`\n",
    "* `keras` is the deep learning modeling language"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Stochastic Gradient Descent (SGD)\n",
    "\n",
    "* In optimization the update formula\n",
    "\n",
    "$$\n",
    "\\beta_{k+1} = \\beta_{k} + a_k p_k,\n",
    "$$\n",
    "  \n",
    "  * step length $a_k \\in \\mathbb{R}$ \n",
    "  * vector direction $p_k$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "* Talyor expansion,\n",
    "$$\n",
    "f(\\beta_{k+1}) = f(\\beta_k + a_k p_k ) \\approx f(\\beta_k) + a_k \\nabla f(\\beta_k) p_k,\n",
    "$$\n",
    "\n",
    "* Choose $p_k$ to reduce $f(x)$ \n",
    "* A simple choice is $p_k =-\\nabla f(\\beta_k)$.\n",
    "\n",
    "c.f.:\n",
    "* Newton's method:$p_k =- (\\nabla^2 f(\\beta_k))^{-1}  \\nabla f(\\beta_k)$\n",
    "* BFGS uses a low-rank matrix to approximate $\\nabla^2 f(\\beta_k)$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "* When sample size and/or number of parameter is big, prohibitively expensive to evaluate gradient\n",
    "* SGD uses a small batch of the sample to evaluate the gradient in each iteration. \n",
    "\n",
    "* SGD involves tuning parameters \n",
    "  * say, batch size\n",
    "  * learning rate\n",
    "\n",
    "* Careful experiments must be carried out before serious implementation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Experiment\n",
    "\n",
    "Use SGD in the PPMLE\n",
    "* sample size 100,000\n",
    "* the number of parameters 100\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    },
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "poisson.loglik = function( b, y, X ) {\n",
    "  b = as.matrix( b )\n",
    "  lambda =  exp( X %*% b )\n",
    "  ell = -mean( -lambda + y *  log(lambda) )\n",
    "  return(ell)\n",
    "}\n",
    "\n",
    "\n",
    "poisson.loglik.grad = function( b, y, X ) {\n",
    "  b = as.matrix( b )\n",
    "  lambda =  as.vector( exp( X %*% b ) )\n",
    "  ell = -colMeans( -lambda * X + y * X )\n",
    "  ell_eta = ell\n",
    "  return(ell_eta)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    },
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "##### generate the artificial data\n",
    "set.seed(898)\n",
    "nn = 1e5; K = 100\n",
    "\n",
    "X = cbind(1, matrix( runif( nn*(K-1) ), ncol = K-1 ) )\n",
    "b0 = rep(1, K) / K\n",
    "y = rpois(nn, exp( X %*% b0 ) )\n",
    "\n",
    "\n",
    "b.init = runif(K); b.init  = 2 * b.init / sum(b.init)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    },
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# and these tuning parameters are related to N and K\n",
    "\n",
    "n = length(y)\n",
    "test_ind = sample(1:n, round(0.2*n) ) \n",
    "\n",
    "# 80% training data\n",
    "# 20% testing data\n",
    "\n",
    "y_test = y[test_ind]\n",
    "X_test = X[test_ind, ]\n",
    "\n",
    "y_train = y[-test_ind ]\n",
    "X_train = X[-test_ind, ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    },
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "point estimate = -0.007249861 0.0138033 0.006121163 0.006204153 0.001798774 -0.009304036 -0.006873972 -0.00481955 -0.007800092 0.02711295 0.02655227 0.008583107 0.005909385 -0.005516035 -0.004789239 -0.003592118 0.001915902 -0.00305892 0.004406357 0.01935639 0.02747918 0.02257842 0.02094568 0.01654139 0.02467052 0.02637046 0.01483604 0.01598381 0.0008255997 0.02621043 0.01620266 -0.0009979067 0.008017293 -0.006191963 -0.005256497 0.01174968 0.005335572 0.02215786 0.01608107 0.02225445 0.01016261 0.01537138 -0.0001712781 0.02720083 0.008683446 -0.008486209 0.01793224 0.005103203 -0.007451151 -0.004670695 0.0249739 -0.003024627 0.02890942 0.01310197 0.02309366 0.01442766 0.003820778 0.02327051 0.02575562 0.02914741 0.0188664 -0.002761642 -0.004392489 -0.002543685 0.02377113 0.0200645 0.01171033 0.007716341 0.02242529 0.02809975 0.009372334 0.004039922 0.01926306 0.01943598 -0.009137019 0.001535105 -0.00656257 0.0123897 0.02772417 0.01842174 -0.005104174 0.02817047 0.02030566 0.02858702 -0.006377652 -0.004298234 0.01333193 0.007131864 0.01649981 0.003661526 0.02973995 -0.001890273 0.004508509 0.01369895 0.008035088 0.005172571 0.00504541 0.002913795 0.007788806 0.02874669 , log_lik =  0.8261549 \n",
      "Time difference of 0.783834 secs\n"
     ]
    }
   ],
   "source": [
    "# optimization parameters\n",
    "\n",
    "# sgd depends on\n",
    "# * eta: the learning rate\n",
    "# * epoch: the averaging small batch\n",
    "# * the initial value\n",
    "\n",
    "set.seed(105)\n",
    "\n",
    "max_iter = 5000\n",
    "min_iter = 20\n",
    "eta=0.01\n",
    "epoch = round( 100*sqrt(K) )\n",
    "\n",
    "\n",
    "b_old = b.init\n",
    "\n",
    "pts0 = Sys.time()\n",
    "# the iteration of gradient\n",
    "for (i in 1:max_iter ){\n",
    "\n",
    "  loglik_old = poisson.loglik(b_old, y_train, X_train)\n",
    "  i_sample = sample(1:length(y_train), epoch, replace = TRUE )\n",
    "  b_new = b_old - eta * poisson.loglik.grad(b_old, y_train[i_sample], X_train[i_sample, ])\n",
    "  loglik_new = poisson.loglik(b_new, y_test, X_test)\n",
    "  b_old = b_new # update\n",
    "\n",
    "  criterion =  loglik_old - loglik_new  \n",
    "  if (  criterion < 0.0001 & i >= min_iter ) break\n",
    "}\n",
    "cat(\"point estimate =\", b_new, \", log_lik = \", loglik_new, \"\\n\")\n",
    "pts1 = Sys.time( ) - pts0\n",
    "print(pts1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    },
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Call:\n",
      "\n",
      "nloptr::nloptr(x0 = b.init, eval_f = poisson.loglik, eval_grad_f = poisson.loglik.grad, \n",
      "    opts = opts, y = y_train, X = X_train)\n",
      "\n",
      "\n",
      "Minimization using NLopt version 2.7.1 \n",
      "\n",
      "NLopt solver status: 4 ( NLOPT_XTOL_REACHED: Optimization stopped because \n",
      "xtol_rel or xtol_abs (above) was reached. )\n",
      "\n",
      "Number of Iterations....: 50 \n",
      "Termination conditions:  xtol_rel: 1e-07\tmaxeval: 5000 \n",
      "Number of inequality constraints:  0 \n",
      "Number of equality constraints:    0 \n",
      "Optimal value of objective function:  0.817239347882672 \n",
      "Optimal value of controls: 0.008377464 0.00223468 0.006802827 0.009527097 -0.009179097 0.001837231 \n",
      "-0.001861563 0.0250962 0.007914374 0.01430903 0.0185239 0.0009192213 \n",
      "-0.003079815 0.02091482 0.01838836 0.02317564 0.007484981 0.02760165 0.02395294 \n",
      "0.02581524 0.0008703182 0.003018651 -0.0008777799 0.005505568 -0.006333724 \n",
      "0.007045993 0.009869454 0.01635177 0.02444754 0.01859429 0.002282465 \n",
      "-0.006204774 0.01787497 0.00871074 0.01634583 0.01452785 0.01535949 0.02114798 \n",
      "0.02882988 0.003990018 0.006488755 0.01821596 0.01224189 -0.001992572 \n",
      "0.009518121 -0.004068174 -0.00955518 -0.008724836 0.01379455 0.01182887 \n",
      "0.02293765 0.01606992 0.01559747 0.02075959 -0.002392985 -0.003346411 \n",
      "0.006898647 0.0120779 0.02070444 0.01023695 0.01356451 0.01390674 0.01992954 \n",
      "0.00914424 0.01823229 0.009599003 0.005063411 0.001639757 -0.003360399 \n",
      "0.004146783 0.0004618288 0.01613158 0.00628123 -0.007416353 0.01045353 \n",
      "0.02667767 0.01690433 0.009531548 0.01430839 0.005220393 0.02352873 0.01921597 \n",
      "0.01270081 0.00527763 0.008045643 0.002385956 0.02469504 0.002604459 0.02668898 \n",
      "-0.01424429 0.01709918 0.008055604 0.007352139 0.01098655 0.002287008 0.0190659 \n",
      "0.0004742784 0.01790932 -0.0007725258 0.02297663\n",
      "\n",
      "\n",
      "Time difference of 5.915949 secs\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "log lik in test data by sgd =  0.8261549 \n",
      "log lik in test data by nlopt =  0.8263522 \n",
      "log lik in test data by oracle =  0.8254042 \n"
     ]
    }
   ],
   "source": [
    "# optimx is too slow for this dataset.\n",
    "# Nelder-Mead method is too slow for this dataset\n",
    "\n",
    "# thus we only sgd with NLoptr\n",
    "\n",
    "opts = list(\"algorithm\"=\"NLOPT_LD_SLSQP\",\"xtol_rel\"=1.0e-7, maxeval = 5000)\n",
    "\n",
    "\n",
    "pts0 = Sys.time( )\n",
    "res_BFGS = nloptr::nloptr( x0=b.init,\n",
    "                 eval_f=poisson.loglik,\n",
    "                 eval_grad_f = poisson.loglik.grad,\n",
    "                 opts=opts,\n",
    "                 y = y_train, X = X_train)\n",
    "print( res_BFGS )\n",
    "pts1 = Sys.time( ) - pts0\n",
    "print(pts1)\n",
    "\n",
    "b_hat_nlopt = res_BFGS$solution\n",
    "\n",
    "\n",
    "#### evaluation in the test sample\n",
    "cat(\"\\n\\n\\n\\n\\n\\n\\n\")\n",
    "cat(\"log lik in test data by sgd = \", poisson.loglik(b_new, y = y_test, X_test), \"\\n\")\n",
    "cat(\"log lik in test data by nlopt = \", poisson.loglik(b_hat_nlopt, y = y_test, X_test), \"\\n\")\n",
    "cat(\"log lik in test data by oracle = \", poisson.loglik(b0, y = y_test, X_test), \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Summary\n",
    "\n",
    "* Mature algorithms for implementation\n",
    "* Theoretical investigation is in progress\n",
    "* Economic applications are emerging"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "* Lehrer and Xie (2017) \n",
    "* Feng, Giglio, and Xiu (2019)\n",
    "* Chinco, Clark-Joseph, and Ye (2019)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": "",
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "4.2.2"
  },
  "rise": {
   "enable_chalkboard": true,
   "scroll": true,
   "theme": "serif"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
